{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omar_\\anaconda3\\envs\\env_cuda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "from transformers import AutoTokenizer, OpenAIGPTForSequenceClassification\n",
    "from transformers import AutoTokenizer, DebertaForSequenceClassification\n",
    "from transformers import AutoTokenizer, RobertaPreLayerNormForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertConfig\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3060\n",
      "GPU 1: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    # List the available GPUs\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"No GPU devices are available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the GPU devices you want to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # Use GPU devices 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "{'translate': 0, 'transfer': 1, 'timer': 2, 'definition': 3, 'meaning_of_life': 4, 'insurance_change': 5, 'find_phone': 6, 'travel_alert': 7, 'pto_request': 8, 'improve_credit_score': 9, 'fun_fact': 10, 'change_language': 11, 'payday': 12, 'replacement_card_duration': 13, 'time': 14, 'application_status': 15, 'flight_status': 16, 'flip_coin': 17, 'change_user_name': 18, 'where_are_you_from': 19, 'shopping_list_update': 20, 'what_can_i_ask_you': 21, 'maybe': 22, 'oil_change_how': 23, 'restaurant_reservation': 24, 'balance': 25, 'confirm_reservation': 26, 'freeze_account': 27, 'rollover_401k': 28, 'who_made_you': 29, 'distance': 30, 'user_name': 31, 'timezone': 32, 'next_song': 33, 'transactions': 34, 'restaurant_suggestion': 35, 'rewards_balance': 36, 'pay_bill': 37, 'spending_history': 38, 'pto_request_status': 39, 'credit_score': 40, 'new_card': 41, 'lost_luggage': 42, 'repeat': 43, 'mpg': 44, 'oil_change_when': 45, 'yes': 46, 'travel_suggestion': 47, 'insurance': 48, 'todo_list_update': 49, 'reminder': 50, 'change_speed': 51, 'tire_pressure': 52, 'no': 53, 'apr': 54, 'nutrition_info': 55, 'calendar': 56, 'uber': 57, 'calculator': 58, 'date': 59, 'carry_on': 60, 'pto_used': 61, 'schedule_maintenance': 62, 'travel_notification': 63, 'sync_device': 64, 'thank_you': 65, 'roll_dice': 66, 'food_last': 67, 'cook_time': 68, 'reminder_update': 69, 'report_lost_card': 70, 'ingredient_substitution': 71, 'make_call': 72, 'alarm': 73, 'todo_list': 74, 'change_accent': 75, 'w2': 76, 'bill_due': 77, 'calories': 78, 'damaged_card': 79, 'restaurant_reviews': 80, 'routing': 81, 'do_you_have_pets': 82, 'schedule_meeting': 83, 'gas_type': 84, 'plug_type': 85, 'tire_change': 86, 'exchange_rate': 87, 'next_holiday': 88, 'change_volume': 89, 'who_do_you_work_for': 90, 'credit_limit': 91, 'how_busy': 92, 'accept_reservations': 93, 'order_status': 94, 'pin_change': 95, 'goodbye': 96, 'account_blocked': 97, 'what_song': 98, 'international_fees': 99, 'last_maintenance': 100, 'meeting_schedule': 101, 'ingredients_list': 102, 'report_fraud': 103, 'measurement_conversion': 104, 'smart_home': 105, 'book_hotel': 106, 'current_location': 107, 'weather': 108, 'taxes': 109, 'min_payment': 110, 'whisper_mode': 111, 'cancel': 112, 'international_visa': 113, 'vaccines': 114, 'pto_balance': 115, 'directions': 116, 'spelling': 117, 'greeting': 118, 'reset_settings': 119, 'what_is_your_name': 120, 'direct_deposit': 121, 'interest_rate': 122, 'credit_limit_change': 123, 'what_are_your_hobbies': 124, 'book_flight': 125, 'shopping_list': 126, 'text': 127, 'bill_balance': 128, 'share_location': 129, 'redeem_rewards': 130, 'play_music': 131, 'calendar_update': 132, 'are_you_a_bot': 133, 'gas': 134, 'expiration_date': 135, 'update_playlist': 136, 'cancel_reservation': 137, 'tell_joke': 138, 'change_ai_name': 139, 'how_old_are_you': 140, 'car_rental': 141, 'jump_start': 142, 'meal_suggestion': 143, 'recipe': 144, 'income': 145, 'order': 146, 'traffic': 147, 'order_checks': 148, 'card_declined': 149}\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset from local CSV file\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "queries = train_df['dialog'].tolist()\n",
    "labels = train_df['intent'].tolist()\n",
    "# added later\n",
    "unique_intents = train_df['intent'].unique()\n",
    "intent_to_label = {intent: label for label, intent in enumerate(unique_intents)}\n",
    "\n",
    "# Load the inference dataset from local CSV file\n",
    "test_file_path = \"test.csv\"\n",
    "\n",
    "# Load test queries from the file\n",
    "with open(test_file_path, \"r\") as file:\n",
    "    inference_queries = [line.strip() for line in file]\n",
    "\n",
    "# Define the number of intent classes\n",
    "num_classes = len(train_df['intent'].unique())\n",
    "print(num_classes)\n",
    "print(intent_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Load a pre-trained BERT model and tokenizer\n",
    "# model_name = \"bert-base-uncased\"\n",
    "# model_name = \"bert-large-uncased-whole-word-masking\"\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "# model_name = \"roberta-large\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "\n",
    "\n",
    "# Move the model to GPUs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,  ..., 149, 149, 149], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Encode the queries and labels using the BERT tokenizer\n",
    "encoded_inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "input_ids = encoded_inputs[\"input_ids\"]\n",
    "attention_mask = encoded_inputs[\"attention_mask\"]\n",
    "labels = torch.tensor([intent_to_label[label] for label in labels]).to(device)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.00000000001, random_state=21)\n",
    "train_masks, val_masks, _, _ = train_test_split(attention_mask, input_ids, test_size=0.00000000001, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 760\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/15 [00:00<?, ?it/s]c:\\Users\\omar_\\anaconda3\\envs\\env_cuda\\lib\\site-packages\\torch\\nn\\parallel\\_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "c:\\Users\\omar_\\anaconda3\\envs\\env_cuda\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn(\"PyTorch is not compiled with NCCL support\")\n",
      "Epoch 1: 100%|██████████| 15/15 [00:19<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 1: 5.005773671468099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 2: 4.786820793151856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 3: 4.36770699818929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 4: 3.9195431391398112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 5: 3.4927379926045736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 6: 3.112372318903605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 7: 2.7689308961232504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 8: 2.451499032974243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 9: 2.171376434961955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 10: 1.9170511643091837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 11: 1.6889657020568847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 12: 1.4788484255472818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 13: 1.2840496063232423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 14: 1.1143947998682657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 15: 0.9630171378453573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 16: 0.8308391571044922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 17: 0.7142441789309184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 15/15 [00:17<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 18: 0.613876211643219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 19: 0.5254504680633545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 20: 0.44997575084368385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 15/15 [00:17<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 21: 0.3882920523484548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 22: 0.3355198323726654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 23: 0.2917487343152364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 24: 0.2573720574378967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 25: 0.2284652014573415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 15/15 [00:17<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 26: 0.20422271986802418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 15/15 [00:17<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 27: 0.18311154047648112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 15/15 [00:17<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 28: 0.1665387213230133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 29: 0.15150078137715658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 15/15 [00:17<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 30: 0.13829084634780883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 31: 0.1267171988884608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 32: 0.11764918814102808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 15/15 [00:18<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 33: 0.10862083385388056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 15/15 [00:17<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 34: 0.10057244847218196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 35: 0.09339784185091654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 15/15 [00:17<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 36: 0.08764501909414928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 37: 0.08337118277947107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 38: 0.0779101217786471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 39: 0.0730539932847023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 40: 0.06921570052703221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 41: 0.06542663872241974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 42: 0.06113864630460739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 43: 0.05847327634692192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 44: 0.05527334536115328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 45: 0.05268031135201454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 15/15 [00:17<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 46: 0.050323533018430074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 47: 0.048782489448785785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 48: 0.046229083091020584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 49: 0.04417743409673373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 50: 0.04212869107723236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 51: 0.04075548872351646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 15/15 [00:17<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 52: 0.03939661433299382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 15/15 [00:17<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 53: 0.037868618965148926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 15/15 [00:17<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 54: 0.03609771877527237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 55: 0.03511850635210673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 56: 0.03355687260627747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 57: 0.03172341547906399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 58: 0.03099258281290531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 15/15 [00:17<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 59: 0.029849824557701746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 15/15 [00:17<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 60: 0.028909991309046746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 61: 0.02810343454281489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 15/15 [00:17<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 62: 0.027244438603520393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 63: 0.026291109745701154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 15/15 [00:17<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for epoch 64: 0.025195595994591712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the BERT model\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "num_epochs = 64\n",
    "\n",
    "# Wrap the model with DataParallel to use multiple GPUs\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        inputs, masks, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs, attention_mask=masks, labels=labels)\n",
    "\n",
    "        # Get the per-GPU loss\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Reduce the per-GPU loss to a scalar\n",
    "        if isinstance(loss, torch.Tensor):\n",
    "            loss = loss.mean()  # Average the loss if it's a tensor\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Average training loss for epoch {epoch + 1}: {avg_train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or serialize the fine-tuned model for inference\n",
    "model.module.save_pretrained(\"saved_model_acc_97.02_epoch64_batch_760_roberta_random21_lr-1e5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 95.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.0\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          91       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "model.module.eval()\n",
    "val_predictions = []\n",
    "val_true_labels = []\n",
    "\n",
    "for batch in tqdm(val_dataloader, desc=\"Evaluating\"):\n",
    "    inputs, masks, labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs, attention_mask=masks)\n",
    "    logits = outputs.logits.to(\"cpu\")  # Move the logits to CPU\n",
    "    predictions = torch.argmax(logits, dim=1)  # Use torch.argmax instead of np.argmax\n",
    "    val_predictions.extend(predictions.tolist())\n",
    "    val_true_labels.extend(labels.to(\"cpu\").tolist())  # Move labels to CPU\n",
    "\n",
    "accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "classification_rep = classification_report(val_true_labels, val_predictions)\n",
    "\n",
    "print(f\"Validation accuracy: {accuracy}\")\n",
    "print(\"Classification report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fine-tuned model for inference\n",
    "with open(\"asnwer.txt\", \"w\") as file:\n",
    "    for query in inference_queries:\n",
    "        encoded_input = tokenizer(query, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids = encoded_input[\"input_ids\"]\n",
    "        attention_mask = encoded_input[\"attention_mask\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predicted_intent_id = torch.argmax(logits, dim=1).item()\n",
    "        predicted_intent = train_df['intent'].unique()[predicted_intent_id]\n",
    "\n",
    "        # Write the predicted intent label to the text file\n",
    "        file.write(f\"{predicted_intent}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
